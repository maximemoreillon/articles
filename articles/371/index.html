<!DOCTYPE html>
<html lang="en-us"><head><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">Deployment of a TensorFlow model to Kubernetes | Maxime Moreillon</title>
<meta property="og:title" content="Deployment of a TensorFlow model to Kubernetes | Maxime Moreillon" />
<meta name="twitter:title" content="Deployment of a TensorFlow model to Kubernetes | Maxime Moreillon" />
<meta itemprop="name" content="Deployment of a TensorFlow model to Kubernetes | Maxime Moreillon" />
<meta name="application-name" content="Deployment of a TensorFlow model to Kubernetes | Maxime Moreillon" />
<meta property="og:site_name" content="" />

<meta name="description" content="">
<meta itemprop="description" content="" />
<meta property="og:description" content="" />
<meta name="twitter:description" content="" />

<meta property="og:locale" content="en-us" />
<meta name="language" content="en-us" />

  <link rel="alternate" hreflang="en" href="https://articles.maximemoreillon.com/articles/371/" title="" />






<meta name="generator" content="Hugo 0.147.8">

    
    <meta property="og:url" content="https://articles.maximemoreillon.com/articles/371/">
  <meta property="og:site_name" content="Maxime Moreillon">
  <meta property="og:title" content="Deployment of a TensorFlow model to Kubernetes">
  <meta property="og:description" content="Let’s imagine that you’ve just finished training your new TensorFlow model and want to start using it in your application(s). One obvious way to do so is to simply import it in the source code of every application that uses it. However, it might be more versatile to keep your model in one place as standalone and simply have applications exchange data with it through API calls. This article will go through the steps of building such a system and deploy the result to Kubernetes.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2020-05-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2021-09-26T00:00:00+00:00">
    <meta property="article:tag" content="AI / ML">
    <meta property="article:tag" content="DevOps">
    <meta property="article:tag" content="TensorFlow">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Deployment of a TensorFlow model to Kubernetes">
  <meta name="twitter:description" content="Let’s imagine that you’ve just finished training your new TensorFlow model and want to start using it in your application(s). One obvious way to do so is to simply import it in the source code of every application that uses it. However, it might be more versatile to keep your model in one place as standalone and simply have applications exchange data with it through API calls. This article will go through the steps of building such a system and deploy the result to Kubernetes.">


    

    <link rel="canonical" href="https://articles.maximemoreillon.com/articles/371/">
    <link href="/style.min.e390ba7da26222f4dc42a349955d76dbbe44e5ce2535a43de5a70633a0a9ec3c.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="https://articles.maximemoreillon.com/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">
    <meta name="color-scheme" content="light dark">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
    
</head>
<body data-theme = "" class="notransition">

<script src="/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js" integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="https://articles.maximemoreillon.com/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title></title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/articles/">
                        Articles
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/tags/">
                        Tags
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">Deployment of a TensorFlow model to Kubernetes</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2020-05-27T00:00:00&#43;00:00" itemprop="datePublished"> May 27, 2020 </time>
                </div>
                
            </header>
            
            <div class="page-content">
                <p>Let’s imagine that you’ve just finished training your new TensorFlow model and want to start using it in your application(s). One obvious way to do so is to simply import it in the source code of every application that uses it. However, it might be more versatile to keep your model in one place as standalone and simply have applications exchange data with it through API calls. This article will go through the steps of building such a system and deploy the result to Kubernetes.</p>
<p>This guide is based on the <a href="https://www.tensorflow.org/tfx/serving/serving_kubernetes">official TensorFlow Serving documentation</a></p>
<h2 id="the-tensorflow-model">The TensorFlow Model</h2>
<p>First, we need a model to work with. For this purpose, here is a snippet taken from the TensorFlow getting started guide that deals with the building and training of a simple Keras model:</p>
<pre tabindex="0"><code># Data loading, preprocessing etc...

# Building the model
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation=&#39;relu&#39;),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

# Compiling the model
model.compile(optimizer=&#39;adam&#39;,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&#39;accuracy&#39;])

# Train the model
model.fit(x_train, y_train, epochs=5)
</code></pre><p>The trained model can then be used within the code so as to make predictions. However, this model would me more useful if it could also be used by other applications, potentially deployed on different computers. To do so, the model can be exposed to HTTP request using a REST API. Although this could be done by using Flask to create an API endpoint for our model, Tensorflow Serving offers a similar solution without requiring complicated setup for developers.</p>
<p>Tensorflow Serving consists of a Docker container inside which the desired model is copied. The container contains the necesssary logic to expose the model to HTTP requests.</p>
<p>To use Tensorflow Serving, one must first export the model using the <code>save</code> function of Keras:</p>
<pre tabindex="0"><code>MODEL_NAME = &#39;mymodel&#39;
MODEL_VERSION = 1
model.save(&#39;./{}/{}/&#39;.format(MODEL_NAME, MODEL_VERSION ))
</code></pre><p>Note how the model name and version are defined.</p>
<p>The model now exists in the folder <code>./mymodel/1/</code>.</p>
<h2 id="preparing-a-tensorflow-serving-container">Preparing a TensorFlow Serving container</h2>
<p>Now, an empty TensorFlow serving container can be pulled from Docker Hub and run locally:</p>
<pre tabindex="0"><code>docker run -d --name serving_base tensorflow/serving
</code></pre><p>With the container running, one can now copy the exported model into it using:</p>
<pre tabindex="0"><code>docker cp ./mymodel serving_base:/models/mymodel
</code></pre><p>The container now contains our model and can be saved as a new image. This can be done by using the docker commit command:</p>
<pre tabindex="0"><code>docker commit --change &#34;ENV MODEL_NAME mymodel&#34; serving_base my-registry/mymodel-serving
</code></pre><p>Note here that my-registry is the URL of the docker registry to push the image to.</p>
<p>Once done, we can get rid of the original TensworFlow serving image</p>
<pre tabindex="0"><code>docker kill serving_base
docker rm serving_base
</code></pre><p>Here, it might be a good idea to check if the container is actually working, so let&rsquo;s run it</p>
<pre tabindex="0"><code>docker run -d -p 8501:8510 my-registry/mymodel-serving
</code></pre><p>Note that 8501 is the port TensorFlow serving uses for its REST API.</p>
<p>A Get request to <code>http://localhost:8501/v1/models/mymodel</code> Should return the following JSON:</p>
<pre tabindex="0"><code>{
 &#34;model_version_status&#34;: [
  {
   &#34;version&#34;: &#34;1&#34;,
   &#34;state&#34;: &#34;AVAILABLE&#34;,
   &#34;status&#34;: {
    &#34;error_code&#34;: &#34;OK&#34;,
    &#34;error_message&#34;: &#34;&#34;
   }
  }
 ]
}
</code></pre><p>If everything is successful so far, the container can be pushed to the registry, which will make it available for Kubernetes to deploy:</p>
<pre tabindex="0"><code>docker push my-registry/mymodel-serving
</code></pre><h2 id="deploying-the-container-to-kubernetes">Deploying the container to Kubernetes</h2>
<p>Now that the container has been pushed to a registry, it can be deployed to our Kubernetes cluster. This is achieved by creating two resources in the cluster: a deployment and a service. The deployment is basically the application itself while the service is here to allow users to reach the deployment from outside the cluster. Here, we will use a NodePort service so that our TensorFlow serving container can be accessed from outside the cluster by simply using a dedicated port. We will choose 30111 for this matter.</p>
<p>Creating those resources is done simply by applying the content of a YAML manifest file with the kubectl command. In our case, here is the content of our kubernetes_manifest.yml file:</p>
<pre tabindex="0"><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: mymodel-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mymodel-serving
  template:
    metadata:
      labels:
        app: mymodel-serving
    spec:
      containers:
      - name: mymodel-serving
        image: my-registry/mymodel-serving
        ports:
        - containerPort: 8501
---
apiVersion: v1
kind: Service
metadata:
  name: mymodel-serving
spec:
  ports:
  - port: 8501
    nodePort: 30111
  selector:
    app: mymodel-serving
  type: NodePort
</code></pre><p>The resources can then be created by executing</p>
<pre tabindex="0"><code>kubectl apply -f kubernetes_manifest.yml
</code></pre><p>The container should now be deployed in the Kubernetes cluster</p>
<h2 id="using-the-container">Using the container</h2>
<p>The AI model deployed in Kubernetes can now be used for predictions. To do so, one must send a POST request to prediction API of the TensorFlow Serving container with a a body consisting of a JSON containing the input data. The model will then reply with its prediction, also in JSON format. Here is an example of how this can be implemented in Python, using the <code>requests</code> library</p>
<pre tabindex="0"><code>image = cv2.imread(image_path)
payload = json.dumps( {&#39;instances&#39;: [image.tolist()]} )
r = requests.post(&#34;http://&lt;IP of the Cluster&gt;:30111/v1/models/mymodel:predict&#34;, data=payload)
</code></pre><p>Note here that the image data sent to the AI model is embedded in an array. This is because of the way TensorFlow serving accepts input data. In our case, the input image is 28x28 pixels so the data sent to the AI model must be have a (n,28,28) shape where n is the number of images to evaluate.</p>

            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
</div>
    <small class="footer_copyright">
        © 2025 Maxime Moreillon.
        
    </small>
</footer>







    
    <script src="https://articles.maximemoreillon.com/js/main.min.4ee188e1744c19816e95a540b2650ed9f033ea0371e74eac8e717355cfca8741.js" integrity="sha256-TuGI4XRMGYFulaVAsmUO2fAz6gNx506sjnFzVc/Kh0E="></script>

    

</body>
</html>
