<!DOCTYPE html>
<html lang="en-us"><head><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s | Maxime Moreillon</title>
<meta property="og:title" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s | Maxime Moreillon" />
<meta name="twitter:title" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s | Maxime Moreillon" />
<meta itemprop="name" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s | Maxime Moreillon" />
<meta name="application-name" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s | Maxime Moreillon" />
<meta property="og:site_name" content="" />

<meta name="description" content="">
<meta itemprop="description" content="" />
<meta property="og:description" content="" />
<meta name="twitter:description" content="" />

<meta property="og:locale" content="en-us" />
<meta name="language" content="en-us" />

  <link rel="alternate" hreflang="en" href="https://articles.maximemoreillon.com/articles/70/" title="" />






<meta name="generator" content="Hugo 0.147.8">

    
    <meta property="og:url" content="https://articles.maximemoreillon.com/articles/70/">
  <meta property="og:site_name" content="Maxime Moreillon">
  <meta property="og:title" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s">
  <meta property="og:description" content="The Nvidia Jetson Nano constitutes a low cost platform for AI applications, ideal for edge computing.However, due to the architecture of its CPU, deploying applications to the SBC can be challenging. In this guide, we’ll install and configure K3s, a lightweight kubernetes distribution made specifically for edge devices. Once done we’ll build and deploy an TensorFlow model in the K3s cluster.
Environment preparation Our objective is to deploy a TensorFlow Serving container in a Kubernetes cluster running on the Jetson Nano. Moreover, this container should fully take advantage of the CUDA capabilities of the Nano. Consequently, some preliminary environment preparation is necessary, namely .The following is based on this guide. Additionally this article assumes that the reader has a Docker container registry available to push to and pull from.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2020-06-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2021-10-07T00:00:00+00:00">
    <meta property="article:tag" content="K3s">
    <meta property="article:tag" content="Tutorials">
    <meta property="article:tag" content="Kubernetes">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s">
  <meta name="twitter:description" content="The Nvidia Jetson Nano constitutes a low cost platform for AI applications, ideal for edge computing.However, due to the architecture of its CPU, deploying applications to the SBC can be challenging. In this guide, we’ll install and configure K3s, a lightweight kubernetes distribution made specifically for edge devices. Once done we’ll build and deploy an TensorFlow model in the K3s cluster.
Environment preparation Our objective is to deploy a TensorFlow Serving container in a Kubernetes cluster running on the Jetson Nano. Moreover, this container should fully take advantage of the CUDA capabilities of the Nano. Consequently, some preliminary environment preparation is necessary, namely .The following is based on this guide. Additionally this article assumes that the reader has a Docker container registry available to push to and pull from.">


    

    <link rel="canonical" href="https://articles.maximemoreillon.com/articles/70/">
    <link href="/style.min.e390ba7da26222f4dc42a349955d76dbbe44e5ce2535a43de5a70633a0a9ec3c.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="https://articles.maximemoreillon.com/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">
    <meta name="color-scheme" content="light dark">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
    
</head>
<body data-theme = "" class="notransition">

<script src="/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js" integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="https://articles.maximemoreillon.com/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title></title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/articles/">
                        Articles
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/tags/">
                        Tags
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">Deploying a TensorFlow model on a Jetson Nano using TensorFlow serving and K3s</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2020-06-01T00:00:00&#43;00:00" itemprop="datePublished"> Jun 1, 2020 </time>
                </div>
                
            </header>
            
            <div class="page-content">
                <p>The Nvidia Jetson Nano constitutes a low cost platform for AI applications, ideal for edge computing.However, due to the architecture of its CPU, deploying applications to the SBC can be challenging. In this guide, we&rsquo;ll install and configure K3s, a lightweight kubernetes distribution made specifically for edge devices. Once done we&rsquo;ll build and deploy an TensorFlow model in the K3s cluster.</p>
<h2 id="environment-preparation">Environment preparation</h2>
<p>Our objective is to deploy a TensorFlow Serving container in a Kubernetes cluster running on the Jetson Nano. Moreover, this container should fully take advantage of the CUDA capabilities of the Nano. Consequently, some preliminary environment preparation is necessary, namely .The following is based on <a href="https://www.virtualthoughts.co.uk/2020/03/24/k3s-and-nvidia-jetson-nano/">this guide</a>. Additionally this article assumes that the reader has a Docker container registry available to push to and pull from.</p>
<h3 id="docker-configuration">Docker configuration</h3>
<p>JetPack, the default Linux distribution that comes with the Jetson Nano, ships with Docker preinstalled. However, Docker must be configured to take advantage of the Jetson Nano&rsquo;s GPU capabilities. This can be done by editing the <code>/etc/docker/daemon.json</code> file. Moreover, if we intend to use a private docker registry served over HTTP, the address of the latter must be specified in the same file. Here is how the file should look like after modifications:</p>
<pre tabindex="0"><code>{
    &#34;default-runtime&#34;: &#34;nvidia&#34;,
    &#34;runtimes&#34;: {
        &#34;nvidia&#34;: {
            &#34;path&#34;: &#34;nvidia-container-runtime&#34;,
            &#34;runtimeArgs&#34;: []
        }
    },
    &#34;insecure-registries&#34; : [&#34;192.168.1.2:5000&#34;]
}
</code></pre><p>Here, 192.168.1.2:5000 is to be replaced by the URL of your registry.</p>
<p>Those changes can be applied by restarting docker:</p>
<pre tabindex="0"><code>sudo systemctl restart docker
</code></pre><h3 id="k3s-installation">K3s installation</h3>
<p>The objective is to deploy an AI model to a Kubernetes cluster running on the Jetson Nano. However, due to the architecture of the latter, most distributions of Kubernetes like Microk8s cannot run on it. This is why we are going to use <a href="https://k3s.io/">K3s</a>, a Kubernetes distribution made specifically for edge devices. K3s can be installed as so:</p>
<pre tabindex="0"><code>curl -sfL https://get.k3s.io | sh -
</code></pre><p>By default, K3s uses containerd as container engine. However, here, we would prefer to use Docker since we&rsquo;ve configured it to fit our needs in the previous step. This can be done by editing the /etc/systemd/system/k3s.service file and adding the &ndash;docker flag to he ExecStart line as follows:</p>
<pre tabindex="0"><code>ExecStart=/usr/local/bin/k3s \
    server \
    --docker
</code></pre><p>K3s must then be restarted using</p>
<pre tabindex="0"><code>sudo systemctl restart k3s
</code></pre><p>Futher details in the <a href="https://rancher.com/docs/k3s/latest/en/advanced/">official documentation</a>.</p>
<p>To check if K3s properly uses the Jetson Nano&rsquo;s GPU, one can deploy the following container in it:</p>
<pre tabindex="0"><code>sudo kubectl run -i -t gpu-check --image=jitteam/devicequery --restart=Never
</code></pre><h2 id="tensorflow-serving">TensorFlow Serving</h2>
<p>First, we are going to need a model to deploy. Here is that of the TensorFlow getting started example, which classifies images from the MNIST dataset:</p>
<pre tabindex="0"><code># Importing TensorFlow
import tensorflow as tf

# Loading the data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Data preprocessing (here, normalization)
x_train, x_test = x_train / 255.0, x_test / 255.0

# Building the model
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation=&#39;relu&#39;),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

# Loss function declaration
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

# Model compilation
model.compile(optimizer=&#39;adam&#39;,
              loss=loss_fn,
              metrics=[&#39;accuracy&#39;])

# Training
model.fit(x_train, y_train, epochs=5)

# Exporting
model.save(&#39;./mymodel/1/&#39;)
</code></pre><p>Running this snippet should generate a folder called mymodel in the working directory, containing our exported model. Thus, the next step is to embed themodel in a TensorFlow Serving container.</p>
<p>The official TensorFlow serving image is unfortunately incompatible with the Jetson Nano&rsquo;s architecture. However, Docker Hub user helmuthvaprovided <a href="https://hub.docker.com/r/helmuthva/jetson-nano-tensorflow-serving">this alternative</a> which works nicely. it can be used just like an usual TensorFlow Serving image:</p>
<pre tabindex="0"><code>docker run -d --name serving_base helmuthva/jetson-nano-tensorflow-serving
docker cp ./mymodel serving_base:/models/mymodel
docker commit --change &#34;ENV MODEL_NAME mymodel&#34; serving_base my-registry/mymodel-serving
</code></pre><p>The container image can then be pushed to our registry, making it available for Kubernetes to deploy:</p>
<pre tabindex="0"><code>docker push my-registry/mymodel-serving
</code></pre><h2 id="kubernetes">Kubernetes</h2>
<p>Now that an image of our TensorFlow serving container is available in our container registry, it is time to pull it in the Kubernetes cluster. to do so, we create a Kubernetes manifest file, for example kubernetes_manifest.yml, with the following content:</p>
<pre tabindex="0"><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: mymodel-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mymodel-serving
  template:
    metadata:
      labels:
        app: mymodel-serving
    spec:
      containers:
      - name: mymodel-serving
        image: my-registry/mymodel-serving
        ports:
        - containerPort: 8501
---
apiVersion: v1
kind: Service
metadata:
  name: mymodel-serving
spec:
  ports:
  - port: 8501
    nodePort: 30111
  selector:
    app: mymodel-serving
  type: NodePort
</code></pre><p>Those resources can be created using kubectl apply</p>
<pre tabindex="0"><code>kubectl apply -f kubernetes_manifest.yml
</code></pre><p>The model should now be deployed to the Kubernetes cluster. This can be verified by pointing a web browser to http://<!-- raw HTML omitted -->/v1/models/mymodel, which should yield the following JSON:</p>
<pre tabindex="0"><code>{
 &#34;model_version_status&#34;: [
  {
   &#34;version&#34;: &#34;1&#34;,
   &#34;state&#34;: &#34;AVAILABLE&#34;,
   &#34;status&#34;: {
    &#34;error_code&#34;: &#34;OK&#34;,
    &#34;error_message&#34;: &#34;&#34;
   }
  }
 ]
}
</code></pre>
            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
</div>
    <small class="footer_copyright">
        © 2025 Maxime Moreillon.
        
    </small>
</footer>







    
    <script src="https://articles.maximemoreillon.com/js/main.min.4ee188e1744c19816e95a540b2650ed9f033ea0371e74eac8e717355cfca8741.js" integrity="sha256-TuGI4XRMGYFulaVAsmUO2fAz6gNx506sjnFzVc/Kh0E="></script>

    

</body>
</html>
